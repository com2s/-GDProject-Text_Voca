{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39e19b90",
      "metadata": {
        "id": "39e19b90"
      },
      "source": [
        "이번 코스에선 문장 데이터를 직접 토큰화하며 어떤 방법이 가장 적합한 단어 조각을 만들어 내는지 실습해보도록 하겠습니다.\n",
        "\n",
        "---\n",
        "\n",
        "이번 코스에서는 KoNLPy, 그중에서도 가장 성능이 준수한 MeCab클래스를 활용해 실습하도록 하겠습니다!\n",
        "\n",
        "클라우드 환경에는 이미 설치되어 있습니다. 아래 링크에서 확인만 해보세요.\n",
        "\n",
        "* [설치하기 - KoNLPy 0.5.2 documentation](https://konlpy.org/ko/latest/install/)\n",
        "설치가 완료된 후엔 아주 간편하게 import 하여 형태소 분석기를 사용하실 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 목차\n",
        "\n",
        "* 데이터 다운로드 및 분석\n",
        "* 공백 기반 토큰화\n",
        "* 형태소 기반 토큰화\n",
        "* 프로젝트:SentencePiece 사용하기\n",
        "* 회고\n",
        "* Reference"
      ],
      "metadata": {
        "id": "8_U-fqJmjSid"
      },
      "id": "8_U-fqJmjSid"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50649553",
      "metadata": {
        "id": "50649553",
        "outputId": "69e44f57-a999-40ee-8d9d-d40d4815d5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()\n",
        "print(mecab.morphs('자연어처리가너무재밌어서밥먹는것도가끔까먹어요'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c5541e",
      "metadata": {
        "id": "e2c5541e"
      },
      "source": [
        "# 데이터 다운로드 및 분석\n",
        "\n",
        "먼저 프로젝트에 사용될 라이브러리를 import 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac132ab0",
      "metadata": {
        "id": "ac132ab0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53edff6",
      "metadata": {
        "id": "b53edff6"
      },
      "source": [
        "그럼 학습환경을 구성하고 데이터를 다운받아 보겠습니다.\n",
        "\n",
        "\\$ wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
        "\\$ mkdir -p ~/aiffel/sp_tokenizer/data\n",
        "\\$ mv korean-english-park.train.tar.gz ~/aiffel/sp_tokenizer/data\n",
        "\\$ cd ~/aiffel/sp_tokenizer/data\n",
        "\\$ tar -xzvf korean-english-park.train.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86420d44",
      "metadata": {
        "id": "86420d44",
        "outputId": "68836d1d-361f-43b1-a030-f346eb01cab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Size: 94123\n",
            "Example:\n",
            ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
            ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
            ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
            ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
            ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
        "\n",
        "with open(path_to_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw))\n",
        "\n",
        "print(\"Example:\")\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9b11f2b",
      "metadata": {
        "id": "a9b11f2b"
      },
      "source": [
        "내려받은 데이터는 한국어의 형태소 분석과 품사 태깅, 기계 번역 연구를 위해 공개된 데이터입니다. 이번에 사용할 데이터는 한국어-영어 병렬을 이루는 말뭉치 중 한국어 부분으로, 전체 병렬 말뭉치는 후에 번역기를 만들며 사용할 예정입니다!\n",
        "\n",
        "자, 데이터가 우리 손으로 들어왔으니 씹고 뜯고 맛볼 차례입니다! 멋진 시각화를 동반한 통계적 분석...까지는 하지 않고요. 최소한의 분석으로 데이터가 얼마나 있고, 어떻게 생겼는지 정도를 직접 확인해 봅시다.\n",
        "\n",
        "문장은 위에서 확인한 것처럼 94123개가 포함되어 있습니다. 우리는 각 문장이 어느 정도의 길이를 가지는지 확인해보겠습니다! 이 과정을 거치면 지나치게 긴 데이터를 삭제하거나 (연산량을 감소시켜 학습 속도가 빨라집니다!) 지나치게 짧은 데이터를 검증 (무조건 필요가 없지는 않습니다, 단어 ↔ 단어 라면 번역을 학습할 수 있겠죠!) 할 수 있습니다. 즉, 데이터를 얼마나 사용할지 타협점을 정의할 수 있습니다.\n",
        "\n",
        "아래 소스는 문장의 최단 길이, 최장 길이, 평균 길이를 구한 후 문장 길이 분포를 막대그래프로 표현해 주는 소스입니다. raw 변수는 앞서 다운로드받은 데이터가 담긴 변수입니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da28c3f",
      "metadata": {
        "id": "5da28c3f",
        "outputId": "e75050da-7752-46ef-a72f-170c39fcf134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장의 최단 길이: 1\n",
            "문장의 최장 길이: 377\n",
            "문장의 평균 길이: 60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/2284205290.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_len = 999\n",
        "max_len = 0\n",
        "sum_len = 0\n",
        "\n",
        "for sen in raw:\n",
        "    length = len(sen)\n",
        "    if min_len > length: min_len = length\n",
        "    if max_len < length: max_len = length\n",
        "    sum_len += length\n",
        "\n",
        "print(\"문장의 최단 길이:\", min_len)\n",
        "print(\"문장의 최장 길이:\", max_len)\n",
        "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
        "\n",
        "sentence_length = np.zeros((max_len), dtype=np.int)\n",
        "\n",
        "for sen in raw:\n",
        "    sentence_length[len(sen)-1] += 1\n",
        "\n",
        "plt.bar(range(max_len), sentence_length, width=1.0)\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b4a573",
      "metadata": {
        "id": "23b4a573"
      },
      "source": [
        "최단 길이 1, 최장 길이 377... 그리고 제법 그럴듯한 막대그래프가 나왔습니다만, 이 결과를 확인하고 드는 생각은 아래와 크게 다르지 않으실 거예요..!\n",
        "\n",
        "1) 길이 1 짜리 문장은 도대체 어떻게 생겨먹었지?\n",
        "\n",
        "2) 앞에 치솟는 임의의 구간은 뭐지? 유의미한 데이터가 담겨있는 부분인가?\n",
        "\n",
        "3) 어디서부터 어디까지 잘라서 쓰지?\n",
        "\n",
        "궁금증을 하나하나 해결해 봅시다! 대체 길이가 1인 문장은 뭘까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa17e936",
      "metadata": {
        "id": "aa17e936",
        "outputId": "99d4de48-0146-4035-8009-9ac45cbe4c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "’\n"
          ]
        }
      ],
      "source": [
        "def check_sentence_with_length(raw, length):\n",
        "    count = 0\n",
        "    \n",
        "    for sen in raw:\n",
        "        if len(sen) == length:\n",
        "            print(sen)\n",
        "            count += 1\n",
        "            if count > 100: return\n",
        "\n",
        "check_sentence_with_length(raw, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80d00e6c",
      "metadata": {
        "id": "80d00e6c"
      },
      "source": [
        "오잉? 하마터면 완전 노이즈인 데이터를 그대로 사용할 뻔했습니다! 왠지 길이별로 확인할 일이 많을 것 같아 함수를 미리 정의해두었는데, 이를 이용해 확인이 필요해 보이는 문장은 모두 확인해보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5f70c88",
      "metadata": {
        "id": "b5f70c88",
        "outputId": "5abb504a-406f-4648-cda1-9eb0278c3c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outlier Index: 11\n",
            "Outlier Index: 19\n",
            "Outlier Index: 21\n"
          ]
        }
      ],
      "source": [
        "for idx, _sum in enumerate(sentence_length):\n",
        "    # 문장의 수가 1500을 초과하는 문장 길이를 추출합니다.\n",
        "    if _sum > 1500:\n",
        "        print(\"Outlier Index:\", idx+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d01345",
      "metadata": {
        "id": "65d01345",
        "outputId": "8b23f998-1300-4017-d99d-174f9e845975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라고 조던이 말했다.\n",
            "- 모르고 있습니다.\n",
            "- 네, 보이는군요.\n",
            "디즈니사만이 아니다.\n",
            "큰 파티는 아니지요.\n",
            "의자는 비어 있었다.\n",
            "이 일은 계속됩니다.\n",
            "나는 크게 실망했다.\n",
            "그 이유는 간단하다.\n",
            "이력서와 자기 소개서\n",
            "시대가 변하고 있다.\n",
            "는 돌발질문을 했다.\n",
            "9. 몇 분간의 명상\n",
            "하와이, 빅 아일랜드\n",
            "키스를 잘 하는 방법\n",
            "키스를 잘 하는 방법\n",
            "스피어스가 뚱뚱한가?\n",
            "산 위를 나는 느낌.\n",
            "세 시간쯤 걸었을까?\n",
            "(아직 읽고있습니까?\n",
            "처음에는 장난이었다.\n",
            "우리는 운이 좋았다.\n",
            "아기가 숨을 멈출 때\n",
            "건물 전체 무너져내려\n",
            "그녀의 아름다운 눈.\n",
            "대답은 다음과 같다.\n",
            "\"사과할 것이 없다.\n",
            "폭탄테러가 공포 유발\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "그는 \"잘 모르겠다.\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n",
            "더 내려야 하는 이유\n",
            "조금은 새침한 샬롯？\n",
            "조금은 새침한 샬롯？\n",
            "케냐 야생동물 고아원\n",
            "경유 1200원대로…\n"
          ]
        }
      ],
      "source": [
        "check_sentence_with_length(raw, 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e5dc2d",
      "metadata": {
        "id": "59e5dc2d"
      },
      "source": [
        "이런... 심지어 중복에 대한 처리도 제대로 하지 않았었네요. 중복 제거는 Python의 기본 자료형 set을 활용할 겁니다. set은 집합을 정의하는 자료형인데, 중복을 허용하지 않아 변환 과정에서 자동으로 중복된 요소를 제거해 주거든요! 대신 list의 순서가 뒤죽박죽될 수 있으니, 만약 번역 데이터처럼 쌍을 이뤄야 하는 경우라면 주의해서 사용하셔야 합니다!\n",
        "\n",
        "중복을 제거한 후, 앞에서 분포를 확인한 소스를 다시 실행시켜 보겠습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01226eca",
      "metadata": {
        "id": "01226eca",
        "outputId": "f6d1b4df-bcbd-4808-b2bf-40c5ef537eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Size: 77591\n",
            "문장의 최단 길이: 1\n",
            "문장의 최장 길이: 377\n",
            "문장의 평균 길이: 64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/390535405.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "min_len = 999\n",
        "max_len = 0\n",
        "sum_len = 0\n",
        "\n",
        "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
        "print(\"Data Size:\", len(cleaned_corpus))\n",
        "\n",
        "for sen in cleaned_corpus:\n",
        "    length = len(sen)\n",
        "    if min_len > length: min_len = length\n",
        "    if max_len < length: max_len = length\n",
        "    sum_len += length\n",
        "\n",
        "print(\"문장의 최단 길이:\", min_len)\n",
        "print(\"문장의 최장 길이:\", max_len)\n",
        "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
        "\n",
        "sentence_length = np.zeros((max_len), dtype=np.int)\n",
        "\n",
        "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
        "    sentence_length[len(sen)-1] += 1\n",
        "\n",
        "plt.bar(range(max_len), sentence_length, width=1.0)\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72978849",
      "metadata": {
        "id": "72978849"
      },
      "source": [
        "이제서야 깔끔한 데이터를 얻은 느낌이 드네요. 데이터의 개수도 17000개가량 줄어 77591 개가 되었습니다.\n",
        "\n",
        "마지막으로 '모든 데이터를 다 사용할 것이냐' 가 문제인데, 후에 미니 배치를 만들 것을 생각하면 모든 데이터를 다 사용하는 것은 연산 측면에서 비효율적입니다. 미니 배치 특성상 각 데이터의 크기가 모두 동일해야 하기 때문에 가장 긴 데이터를 기준으로 Padding 처리를 해야 합니다. 위의 데이터에서 만약 길이가 100인 문장까지만 사용한다면 데이터는 [ (77591 - 길이 100 초과 문장 수) x 100 ] 의 형태를 갖겠지만 모두 사용할 경우 [ 77591 x 377 ] 로 전자보다 최소 3.7배 큰 메모리를 차지합니다. 학습 시간도 그만큼 더 오래 걸리고요.\n",
        "\n",
        "길이별로 정렬하여 미니 배치를 구성해 Padding을 최소화하는 방법도 있지만 이는 데이터를 섞는 데 편향성이 생길 수 있으므로 지양해야 합니다. 여기서는 길이 150 이상의 데이터를 제거하고 사용하도록 할게요!\n",
        "\n",
        "그리고 앞서 확인한 것처럼 너무 짧은 데이터는 오히려 노이즈로 작용할 수 있습니다. 따라서 길이가 10 미만인 데이터도 제거하도록 하죠!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad9f78d",
      "metadata": {
        "id": "cad9f78d",
        "outputId": "ab280055-8a7d-421c-d8d9-737f329fe949"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/1483434014.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_len = 150\n",
        "min_len = 10\n",
        "\n",
        "# 길이 조건에 맞는 문장만 선택합니다.\n",
        "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
        "\n",
        "# 분포도를 다시 그려봅니다.\n",
        "sentence_length = np.zeros((max_len), dtype=np.int)\n",
        "\n",
        "for sen in filtered_corpus:\n",
        "    sentence_length[len(sen)-1] += 1\n",
        "\n",
        "plt.bar(range(max_len), sentence_length, width=1.0)\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa0e57a",
      "metadata": {
        "id": "dfa0e57a"
      },
      "source": [
        "이제 정말 사용할 준비가 된 것 같죠? 본격적인 작업을 시작해봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c46140",
      "metadata": {
        "id": "c9c46140"
      },
      "source": [
        "# 공백 기반 토큰화\n",
        "\n",
        "배운 순서대로, 먼저 공백 기반 토큰화를 진행해 봅시다!\n",
        "\n",
        "정제된 데이터를 공백 기반으로 토큰화하여 list에 저장한 후, 아래 tokenize() 함수를 사용해 단어 사전과 Tensor 데이터를 얻으세요! 그리고 단어 사전의 크기를 확인하세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fcba40",
      "metadata": {
        "id": "e6fcba40"
      },
      "outputs": [],
      "source": [
        "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70b3e6f",
      "metadata": {
        "id": "d70b3e6f"
      },
      "outputs": [],
      "source": [
        "split_corpus = []\n",
        "\n",
        "for kor in filtered_corpus:\n",
        "    split_corpus.append(kor.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30f10f58",
      "metadata": {
        "id": "30f10f58"
      },
      "source": [
        "이제 공백 기반 토큰화를 진행한 후, 단어 사전의 길이를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5dd704",
      "metadata": {
        "id": "be5dd704",
        "outputId": "9987eb45-e6d3-4180-f4f7-a45f44edf946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split Vocab Size: 237435\n"
          ]
        }
      ],
      "source": [
        "split_tensor, split_tokenizer = tokenize(split_corpus)\n",
        "\n",
        "print(\"Split Vocab Size:\", len(split_tokenizer.index_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ca0b7e",
      "metadata": {
        "id": "57ca0b7e",
        "outputId": "184a93de-f3f0-4f4c-b0b2-b9be1c83fbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 : 이\n",
            "1 : 밝혔다.\n",
            "2 : 있다.\n",
            "3 : 말했다.\n",
            "4 : 수\n",
            "5 : 있는\n",
            "6 : 그는\n",
            "7 : 대한\n",
            "8 : 위해\n",
            "9 : 전했다.\n",
            "10 : 지난\n",
            "11 : 이번\n"
          ]
        }
      ],
      "source": [
        "# 아래의 코드로 생성된 단어 사전을 확인해 볼 수 있습니다.\n",
        "\n",
        "for idx, word in enumerate(split_tokenizer.word_index):\n",
        "    print(idx, \":\", word)\n",
        "\n",
        "    if idx > 10: break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59ef75ca",
      "metadata": {
        "id": "59ef75ca"
      },
      "source": [
        "동사로 이루어진 단어를 살피면 공백 기반 토큰화의 문제점을 확인할 수 있습니다. 1번 단어인 밝혔다. 는 밝히다 , 밝다 등과 유사한 의미를 지니고 있음에도 전혀 다른 단어로 분류되겠죠? 이 때문에 공백 기반 토큰화는 불필요하게 큰 단어 사전을 가지게 되며 이는 연산량 증가로 이어집니다.\n",
        "\n",
        "만일 밝 + 혔다 라고 토큰화했다면 어땠을까요? 밝 + 히다, 밝 + 다 같은 구절이 등장했을 때, 공통된 어절인 밝 은 하나로 묶여 학습 중에 의미를 파악하기가 수월해지겠죠? 동시에 단어 사전도 효율적으로 축소될 것입니다. 이를 위해 형태소 분석기가 존재합니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98301e9d",
      "metadata": {
        "id": "98301e9d"
      },
      "source": [
        "# 형태소 기반 토큰화\n",
        "\n",
        "한국어 형태소 분석기는 대표적으로 Khaiii와 KoNLPy가 사용됩니다. 이번 코스에서는 KoNLPy, 그중에서도 가장 성능이 준수한 MeCab클래스를 활용해 실습하도록 하겠습니다!\n",
        "\n",
        "앞서 작성했던 코드를 활용해 MeCab 기반으로 생성된 단어 사전과 Tensor 데이터를 얻어 봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fbddf3",
      "metadata": {
        "id": "73fbddf3"
      },
      "outputs": [],
      "source": [
        "def mecab_split(sentence):\n",
        "    return mecab.morphs(sentence)\n",
        "\n",
        "mecab_corpus = []\n",
        "\n",
        "for kor in filtered_corpus:\n",
        "    mecab_corpus.append(mecab_split(kor))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf87392",
      "metadata": {
        "id": "6bf87392"
      },
      "source": [
        "이제 형태소 기반 토큰화를 진행한 후, 단어 사전의 길이를 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ed6b42",
      "metadata": {
        "id": "71ed6b42",
        "outputId": "5d5329ee-23ce-4c02-9a2a-4be1cbdf352f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MeCab Vocab Size: 52279\n"
          ]
        }
      ],
      "source": [
        "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
        "\n",
        "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848bd1e5",
      "metadata": {
        "id": "848bd1e5"
      },
      "source": [
        "앞서 실습했던 공백 기반 단어 사전에 비해 단어 수가 현저히 줄어든 것을 확인하셨을 겁니다. 이는 곧 연산량의 감소로 이어져 더 빠른 학습을 가능케 하고, 심지어 모델이 튜닝해야 하는 매개변수(Parameter) 수가 줄어들어 학습도 더 잘 된답니다! 적어도 한국어를 처리할 때는 공백 기반 토큰화를 절대 지양하셔야 해요!\n",
        "\n",
        "자주 사용되는 SentencePiece같은 Subword 기반 토큰화보다 형태소 분석기가 좋은 성능을 내는 사례들이 종종 있는데요, ETRI에서 발표한 한국어 BERT 모델인 KorBERT가 대표적인 사례 중 하나입니다. 아래 웹페이지를 방문하면 모델의 자세한 구조뿐 아니라 KorBERT 모델을 5가지 자연어 처리 태스크를 기준으로 평가했던 흥미로운 결과까지 살펴보실 수 있습니다!\n",
        "\n",
        "* [공공 인공지능 오픈 API·DATA 서비스 포털](https://aiopen.etri.re.kr/service_dataset.php)\n",
        "\n",
        "자연어 처리에서 토크나이저가 성능에 미치는 영향도가 크다는 것은 주지의 사실입니다만, 위 링크에서 발표된 평가 결과를 살펴볼 때 몇 가지 생각해 볼 만한 지점이 있습니다.\n",
        "\n",
        "아래 질문들에 대해 스스로 생각해 보고 본인의 생각을 정리해서 답변해 보시기 바랍니다. 사실 정답이 있는 문제는 아니기 때문입니다.\n",
        "\n",
        "https://lms.aiffel.io/course/366/node/457/step/3043"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b9705e8",
      "metadata": {
        "id": "4b9705e8"
      },
      "source": [
        "지금까지 문장을 Tensor로 Encoding하는 과정을 배웠는데요.\n",
        "후에 모델이 생성한 Tensor를 문장으로 Decoding하는 과정도 필요하겠죠?\n",
        "\n",
        "tokenizer.sequences_to_texts() 함수를 사용하여 Decoding\n",
        "tokenizer.index_word 를 사용하여 Decoding\n",
        "\n",
        "두 가지 방법으로 mecab_tensor[100] 을 원문으로 되돌려 보세요!\n",
        "(여기서 띄어쓰기는 고려하지 않습니다!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0459a4",
      "metadata": {
        "id": "1d0459a4",
        "outputId": "f5830715-35da-4c8b-8aa0-a81886083426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저 는 ap 라디오 뉴스 의 존 벨몬트 였 습니다 . clinton global initiative 클린턴 글로벌 이니셔티브 , 클린턴 전 대통령 이 창설 한 자선 회의\n"
          ]
        }
      ],
      "source": [
        "# Case 1\n",
        "texts = mecab_tokenizer.sequences_to_texts([mecab_tensor[100]])\n",
        "print(texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "992aa283",
      "metadata": {
        "id": "992aa283",
        "outputId": "7840bf1c-0742-4b51-df30-3e407169701a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저 는 ap 라디오 뉴스 의 존 벨몬트 였 습니다 . clinton global initiative 클린턴 글로벌 이니셔티브 , 클린턴 전 대통령 이 창설 한 자선 회의 \n"
          ]
        }
      ],
      "source": [
        "# Case 2\n",
        "sentence = \"\"\n",
        "\n",
        "for w in mecab_tensor[100]:\n",
        "    if w == 0: continue\n",
        "    sentence += mecab_tokenizer.index_word[w] + \" \"\n",
        "\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf85e79",
      "metadata": {
        "id": "1cf85e79"
      },
      "source": [
        "# 프로젝트: SentencePiece 사용하기\n",
        "\n",
        "라이브러리 버전을 확인해 봅니다\n",
        "\n",
        "----\n",
        "사용할 라이브러리 버전을 둘러봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914dd4ff",
      "metadata": {
        "id": "914dd4ff",
        "outputId": "47ee3e0a-de70-4238-ea33-d7b646bdfb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "1.21.4\n",
            "3.4.3\n",
            "0.5.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import konlpy\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(plt.__version__)\n",
        "print(konlpy.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "015c4cc8",
      "metadata": {
        "id": "015c4cc8"
      },
      "source": [
        "## 루브릭\n",
        "\n",
        "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
        "\n",
        "-----\n",
        "평가문항\t상세기준\n",
        "\n",
        "1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?\n",
        "\n",
        "> 코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?\n",
        "\n",
        "2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?\n",
        "\n",
        "> SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.\n",
        "\n",
        "3. SentencePiece의 성능을 다각도로 비교분석하였는가?\n",
        "\n",
        "> SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130b67ed",
      "metadata": {
        "id": "130b67ed"
      },
      "source": [
        "## Step 1. SentencePiece 설치하기\n",
        "\n",
        "SentencePiece는 Google에서 제공하는 오픈소스 기반 Sentence Tokenizer/Detokenizer 로서, BPE와 unigram 2가지 subword 토크나이징 모델 중 하나를 선택해서 사용할 수 있도록 패키징한 것입니다. 아래 링크의 페이지에서 상세한 내용을 파악할 수 있습니다.\n",
        "\n",
        "* [google/sentencepiece](https://github.com/google/sentencepiece)\n",
        "\n",
        "위 페이지의 서두에서도 언급하고 있듯, SentencePiece는 딥러닝 자연어처리 모델의 앞부분에 사용할 목적으로 최적화되어 있는데, 최근 pretrained model들이 거의 대부분 SentencePiece를 tokenizer로 채용하면서 사실상 표준의 역할을 하고 있습니다.\n",
        "\n",
        "다음과 같이 설치를 진행합니다. SentencePiece는 python에서 쓰라고 만들어진 라이브러리는 아니지만 편리한 파이썬 wrapper를 아래와 같이 제공하고 있습니다.\n",
        "\n",
        "$ pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a026f0",
      "metadata": {
        "id": "28a026f0",
        "outputId": "e5a8a075-c5fd-41de-f8d1-cc59821ac93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "124d7fda",
      "metadata": {
        "id": "124d7fda"
      },
      "source": [
        "## Step 2. SentencePiece 모델 학습\n",
        "\n",
        "앞서 배운 tokenize() 함수를 기억하나요? 다시 한번 상기시켜드릴게요!\n",
        "\n",
        "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, tokenizer\n",
        "    \n",
        "위와 같이 tf.keras.preprocessing.text.Tokenizer에 corpus를 주고 tokenizer.fit_on_texts(corpus)을 하면 토크나이저 내부적으로 단어사전과 토크나이저 기능을 corpus에 맞춤형으로 자동 생성해 주는 것입니다.\n",
        "\n",
        "그럼 이를 위해서 SentencePiece 모델을 학습하는 과정을 거쳐야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99110e28",
      "metadata": {
        "id": "99110e28",
        "outputId": "2adccf65-1d51-4a72-d412-11a2cd71e97a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
            "  input_format: \n",
            "  model_prefix: korean_spm\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 76908 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=4996369\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=1317\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 76908 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 174340 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 76908\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 237965\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 237965 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=92555 obj=14.853 num_tokens=523272 num_tokens/piece=5.65363\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82083 obj=13.516 num_tokens=525776 num_tokens/piece=6.40542\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=61555 obj=13.5533 num_tokens=546907 num_tokens/piece=8.88485\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=61506 obj=13.5101 num_tokens=547350 num_tokens/piece=8.89913\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46126 obj=13.6926 num_tokens=575369 num_tokens/piece=12.4739\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46126 obj=13.6493 num_tokens=575466 num_tokens/piece=12.476\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34594 obj=13.8894 num_tokens=606014 num_tokens/piece=17.5179\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34594 obj=13.8387 num_tokens=606012 num_tokens/piece=17.5178\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25945 obj=14.1301 num_tokens=637532 num_tokens/piece=24.5724\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25945 obj=14.0747 num_tokens=637568 num_tokens/piece=24.5738\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19458 obj=14.4091 num_tokens=670960 num_tokens/piece=34.4825\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19458 obj=14.3468 num_tokens=670999 num_tokens/piece=34.4845\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14593 obj=14.7196 num_tokens=705636 num_tokens/piece=48.3544\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14593 obj=14.648 num_tokens=705645 num_tokens/piece=48.355\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10944 obj=15.0875 num_tokens=741620 num_tokens/piece=67.765\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10944 obj=15.007 num_tokens=741624 num_tokens/piece=67.7654\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.3757 num_tokens=769363 num_tokens/piece=87.4276\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.307 num_tokens=769367 num_tokens/piece=87.4281\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 376816 Nov 29 06:37 korean_spm.model\r\n",
            "-rw-r--r-- 1 root root 146213 Nov 29 06:37 korean_spm.vocab\r\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
        "\n",
        "vocab_size = 8000\n",
        "\n",
        "with open(temp_file, 'w') as f:\n",
        "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
        "        f.write(str(row) + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
        ")\n",
        "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
        "\n",
        "!ls -l korean_spm*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "090a1a02",
      "metadata": {
        "id": "090a1a02"
      },
      "source": [
        "위 코드를 실행하면 정상적으로 SentencePiece 모델 학습이 완료된 후 korean_spm.model 파일과 korean_spm.vocab vocabulary 파일이 생성되었음을 확인할 수 있습니다.\n",
        "\n",
        "그럼 이렇게 학습된 SentencePiece 모델을 어떻게 활용하는지 살펴보겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb46440b",
      "metadata": {
        "id": "bb46440b",
        "outputId": "473931b3-7927-4ea5-8174-26dbe2bb32af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1243, 11, 302, 7, 3608, 11, 287, 38, 3]\n",
            "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
            "아버지가방에들어가신다.\n"
          ]
        }
      ],
      "source": [
        "s = spm.SentencePieceProcessor()\n",
        "s.Load('korean_spm.model')\n",
        "\n",
        "# SentencePiece를 활용한 sentence -> encoding\n",
        "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
        "print(tokensIDs)\n",
        "\n",
        "# SentencePiece를 활용한 sentence -> encoded pieces\n",
        "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
        "\n",
        "# SentencePiece를 활용한 encoding -> sentence 복원\n",
        "print(s.DecodeIds(tokensIDs))\n",
        "\n",
        "# 어떻습니까? SentencePiece의 토크나이징 실력이 괜찮은 것 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0071eac",
      "metadata": {
        "id": "b0071eac"
      },
      "source": [
        "## Step 3. Tokenizer 함수 작성\n",
        "\n",
        "우리는 위에서 훈련시킨 SentencePiece를 활용하여 위 함수와 유사한 기능을 하는 sp_tokenize() 함수를 정의할 겁니다. 하지만 SentencePiece가 동작하는 방식이 단순 토큰화와는 달라 완전히 동일하게는 정의하기 어렵습니다. 그러니 아래 조건을 만족하는 함수를 정의하도록 하습니다.\n",
        "\n",
        "> 1. 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list 를 전달합니다.\n",
        "\n",
        "> 2. 생성된 vocab 파일을 읽어와 { <word\\> : <idx\\> } 형태를 가지는 word_index 사전과 { <idx\\> : <word\\>} 형태를 가지는 index_word 사전을 생성하고 함께 반환합니다.\n",
        "\n",
        "> 3. 리턴값인 tensor 는 앞의 함수와 동일하게 토큰화한 후 Encoding된 문장입니다. 바로 학습에 사용할 수 있게 Padding은 당연히 해야겠죠?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec2d746",
      "metadata": {
        "id": "dec2d746"
      },
      "outputs": [],
      "source": [
        "def sp_tokenize(s, corpus):\n",
        "\n",
        "    tensor = []\n",
        "\n",
        "    for sen in corpus:\n",
        "        tensor.append(s.EncodeAsIds(sen))\n",
        "\n",
        "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
        "        vocab = f.readlines()\n",
        "\n",
        "    word_index = {}\n",
        "    index_word = {}\n",
        "\n",
        "    for idx, line in enumerate(vocab):\n",
        "        word = line.split(\"\\t\")[0]\n",
        "\n",
        "        word_index.update({word:idx})\n",
        "        index_word.update({idx:word})\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, word_index, index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd93f8c",
      "metadata": {
        "id": "ebd93f8c",
        "outputId": "be3530be-40e9-40f1-a1a5-1e670510c643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1956 5665    5    4 7975 1990    3    0    0    0    0    0    0    0]\n",
            " [ 107 1641  101    4    0  417   11    4   14    0 1976    3    3    3]]\n"
          ]
        }
      ],
      "source": [
        "#sp_tokenize(s, corpus) 사용예제\n",
        "\n",
        "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
        "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005f1b20",
      "metadata": {
        "id": "005f1b20"
      },
      "source": [
        "## Step 4. 네이버 영화리뷰 감정 분석 문제에 SentencePiece 적용해 보기\n",
        "\n",
        "[네이버 영화리뷰 감정 분석 태스크](https://github.com/e9t/nsmc/)가 있습니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용하게 되는데요.\n",
        "\n",
        "만약 이 문제에서 tokenizer를 SentencePiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? KoNLPy에 있는 Mecab, kkma, Okt 등과 비교해보세요.\n",
        "\n",
        "1. 네이버 영화리뷰 감정 분석 코퍼스에 SentencePiece를 적용시킨 모델 학습하기\n",
        "2. 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
        "3. 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정 분석 모델을 재학습하기\n",
        "4. KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
        "5. SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
        "\n",
        "Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82032cda",
      "metadata": {
        "id": "82032cda"
      },
      "source": [
        "### 라이브러리 임포팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bafdf3c2",
      "metadata": {
        "id": "bafdf3c2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import konlpy\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb880d2",
      "metadata": {
        "id": "5fb880d2"
      },
      "source": [
        "### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7991ef6",
      "metadata": {
        "id": "a7991ef6",
        "outputId": "7e207bb0-8ddf-43c1-b5d0-8b0cb2dfb38c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                           document  label\n",
              "0  6270596                                                굳 ㅋ      1\n",
              "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 데이터를 읽어봅시다. \n",
        "train_data = pd.read_table('~/aiffel/text_preprocess/ratings_train.txt')\n",
        "test_data = pd.read_table('~/aiffel/text_preprocess/ratings_test.txt')\n",
        "\n",
        "display(train_data.head())\n",
        "display(test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea299747",
      "metadata": {
        "id": "ea299747",
        "outputId": "8108d0a0-9bf8-4d6c-bbf4-260030289ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150000\n",
            "50000\n"
          ]
        }
      ],
      "source": [
        "# 데이터 크기 확인\n",
        "print(len(train_data))\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc9010a6",
      "metadata": {
        "id": "bc9010a6",
        "outputId": "2e3cd663-f686-4189-fc9e-041672971b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146182\n",
            "49157\n"
          ]
        }
      ],
      "source": [
        "# 중복되는 데이터 제거\n",
        "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "\n",
        "# 결측치가 있는 행 제거\n",
        "train_data = train_data.dropna()\n",
        "test_data = test_data.dropna()\n",
        "\n",
        "# 데이터 크기 다시 확인\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ed008f",
      "metadata": {
        "id": "73ed008f"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c7ff9a",
      "metadata": {
        "id": "32c7ff9a",
        "outputId": "67caeb2b-a718-4a0a-be83-4cc38dd4cc54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/3655971363.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
              "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 학습 데이터 전처리\n",
        "# 한글과 공백을 제외한 문자들을 모두 공백으로 바꾼다.\n",
        "\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfccfe8",
      "metadata": {
        "id": "6bfccfe8",
        "outputId": "d657c007-2430-4f70-9fab-5cbb23b8eb12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31/3173845585.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "1  9274899                                                 0\n",
              "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 테스트 데이터 전처리\n",
        "# 한글과 공백을 제외한 문자들을 모두 공백으로 바꾼다.\n",
        "\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c99dbfc",
      "metadata": {
        "id": "2c99dbfc",
        "outputId": "b00d2bc2-feb2-473f-ca38-802a723073a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Size: 146182\n",
            "문장의 최단 길이: 0\n",
            "문장의 최장 길이: 140\n",
            "문장의 평균 길이: 32\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 데이터의 문장 길이 조절\n",
        "\n",
        "min_len = 999\n",
        "max_len = 0\n",
        "sum_len = 0\n",
        "\n",
        "print(\"Data Size:\", len(train_data))\n",
        "\n",
        "for sen in train_data['document']:\n",
        "    length = len(sen)\n",
        "    if min_len > length: min_len = length\n",
        "    if max_len < length: max_len = length\n",
        "    sum_len += length\n",
        "\n",
        "print(\"문장의 최단 길이:\", min_len)\n",
        "print(\"문장의 최장 길이:\", max_len)\n",
        "print(\"문장의 평균 길이:\", sum_len // len(train_data))\n",
        "\n",
        "sentence_length = np.zeros((max_len), dtype=np.int64)\n",
        "\n",
        "for sen in train_data['document']: \n",
        "    sentence_length[len(sen)-1] += 1\n",
        "\n",
        "plt.bar(range(max_len), sentence_length, width=1.0)\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8160d73a",
      "metadata": {
        "id": "8160d73a",
        "outputId": "bbff2152-cadc-4d3d-9a74-d2d0395dee9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장의 길이가 50 보다 긴 문장의 비율은 16.116211298244654 %입니다. \n"
          ]
        }
      ],
      "source": [
        "length_check = 50\n",
        "i = 0\n",
        "\n",
        "for sen in train_data['document']:\n",
        "    length = len(sen)\n",
        "    if length > length_check: i += 1\n",
        "        \n",
        "rate = i*100/len(train_data)\n",
        "print(\"문장의 길이가\", length_check, \"보다 긴 문장의 비율은\", rate, \"%입니다. \"  )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f5b62cd",
      "metadata": {
        "id": "3f5b62cd"
      },
      "source": [
        "* 위에서 데이터의 문장 길이 분포를 보니 대부분의 데이터가 해당되는 길이인 50개 안 쪽으로 두면 될 것으로 보인다.\n",
        "* 문장의 길이가 0인 데이터는 필요 없으므로 최소길이는 1로 둔다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d13a4e",
      "metadata": {
        "id": "43d13a4e",
        "outputId": "b4cda6b3-c170-4953-f177-ecbbab211a0f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_len = 50\n",
        "min_len = 1\n",
        "\n",
        "# 길이 조건에 맞는 문장만 선택합니다.\n",
        "filtered_train = [s for s in train_data['document'] if (len(s) <= max_len) & (len(s) >= min_len)]\n",
        "\n",
        "# 분포도를 다시 그려봅니다.\n",
        "sentence_length = np.zeros((max_len + 1), dtype=np.int64)\n",
        "\n",
        "for sen in filtered_train:\n",
        "    sentence_length[len(sen)] += 1\n",
        "\n",
        "plt.bar(range(max_len+1), sentence_length, width=1.0)\n",
        "plt.title(\"Sentence Length Distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72683ab5",
      "metadata": {
        "id": "72683ab5",
        "outputId": "dc57915b-8d7f-4e8b-9e58-a55463fd14a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5403919</td>\n",
              "      <td>막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                               document  label\n",
              "0   9976970                      아 더빙 진짜 짜증나네요 목소리      0\n",
              "1   3819312             흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
              "2  10265843                      너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019              교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
              "4   5403919  막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움      0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7898805</td>\n",
              "      <td>음악이 주가 된 최고의 음악영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "1  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "2  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "3  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
              "4  7898805                          음악이 주가 된 최고의 음악영화      1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 테스트 데이터에도 적용하여 새로운 데이터로 만든다.\n",
        "\n",
        "filtered_train = [s for s in train_data['document'] if (len(s) <= max_len) & (len(s) >= min_len)]\n",
        "filtered_test = [s for s in test_data['document'] if (len(s) <= max_len) & (len(s) >= min_len)]\n",
        "\n",
        "train_list = list(set(filtered_train))\n",
        "test_list = list(set(filtered_test))\n",
        "\n",
        "train_df = pd.DataFrame(train_list)\n",
        "test_df = pd.DataFrame(test_list)\n",
        "\n",
        "new_train_df = pd.merge(train_data, train_df, how='inner', left_on='document', right_on=0)\n",
        "new_test_df = pd.merge(test_data, test_df, how='inner', left_on='document', right_on=0)\n",
        "\n",
        "train_data = new_train_df[['id', 'document', 'label']]\n",
        "test_data = new_test_df[['id', 'document', 'label']]\n",
        "\n",
        "display(train_data.head())\n",
        "display(test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612c4540",
      "metadata": {
        "id": "612c4540",
        "outputId": "6e93bcad-1ae9-4a05-d3bf-6da59aecae2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터: 122232\n",
            "테스트 데이터: 41071\n"
          ]
        }
      ],
      "source": [
        "print('학습 데이터:',len(train_data))\n",
        "print('테스트 데이터:',len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a45e85",
      "metadata": {
        "id": "34a45e85"
      },
      "source": [
        "### sp_tokenize\n",
        "\n",
        "step 2,3 에서 사용한 함수들을 다시 확인해보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1e5893",
      "metadata": {
        "id": "2b1e5893"
      },
      "outputs": [],
      "source": [
        "# sp_tokenize로 토큰화\n",
        "\n",
        "X_train, X_train_word_index, X_train_index_word = sp_tokenize(s, train_data['document'])\n",
        "X_test, X_test_word_index, X_test_index_word = sp_tokenize(s, test_data['document'])\n",
        "\n",
        "# label 값을 y_train, y_test로 둔다.\n",
        "\n",
        "y_train = np.array(list(train_data['label']))\n",
        "y_test = np.array(list(test_data['label']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ac17c0",
      "metadata": {
        "id": "b3ac17c0",
        "outputId": "cb4aa56f-5645-4fa6-ef52-a5dd85c9c6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train\n",
            "[[ 141  106 2611  912 4856    4 4856  752   69  554  514 2648    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [   4 7663  466 1756  146   14  439 3174 2766 1791  175  408  381   41\n",
            "  4189    4   11 7570   29 1311  230   69    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [1328  437    0  266  254  591   95  146   10 1960    5 1011  703  249\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n",
            "[0 1 0]\n",
            "\n",
            "test\n",
            "[[   4 7888    4    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [   4 7826  168   25 1089  344  108  193 5571  166 4289  644    4 3363\n",
            "    10  106  377 7639 2506    0   94    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]\n",
            " [ 188  416  100   10  531  423 2092  933  156  510 1038   75   14 3165\n",
            "   180    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]]\n",
            "[1 0 0]\n"
          ]
        }
      ],
      "source": [
        "# 토큰화 결과 확인\n",
        "\n",
        "print('train')\n",
        "print(X_train[:3])\n",
        "print(y_train[:3])\n",
        "print()\n",
        "\n",
        "print('test')\n",
        "print(X_test[:3])\n",
        "print(y_test[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ea4a6a",
      "metadata": {
        "id": "75ea4a6a"
      },
      "outputs": [],
      "source": [
        "# validation set 만들기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 일반적으로 훈련 데이터셋과 검증 데이터셋은 8:2 로 나눈다.\n",
        "train_input, val_input, train_target, val_target = train_test_split(X_train, y_train, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    random_state=34)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802369ba",
      "metadata": {
        "id": "802369ba"
      },
      "source": [
        "### 모델 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b21e09",
      "metadata": {
        "id": "c1b21e09",
        "outputId": "6b6650a6-9fe4-4121-bd2c-0fd5df8aa626"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
            "  input_format: \n",
            "  model_prefix: korean_spm\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
            "trainer_interface.cc(385) LOG(INFO) Loaded all 76908 sentences\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(466) LOG(INFO) all chars count=4996369\n",
            "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
            "trainer_interface.cc(487) LOG(INFO) Alphabet size=1317\n",
            "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
            "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 76908 sentences.\n",
            "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(194) LOG(INFO) Initialized 174340 seed sentencepieces\n",
            "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 76908\n",
            "trainer_interface.cc(537) LOG(INFO) Done! 237965\n",
            "unigram_model_trainer.cc(489) LOG(INFO) Using 237965 sentences for EM training\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=92555 obj=14.853 num_tokens=523272 num_tokens/piece=5.65363\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=82083 obj=13.516 num_tokens=525776 num_tokens/piece=6.40542\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=61555 obj=13.5533 num_tokens=546907 num_tokens/piece=8.88485\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=61506 obj=13.5101 num_tokens=547350 num_tokens/piece=8.89913\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46126 obj=13.6926 num_tokens=575369 num_tokens/piece=12.4739\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46126 obj=13.6493 num_tokens=575466 num_tokens/piece=12.476\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34594 obj=13.8894 num_tokens=606014 num_tokens/piece=17.5179\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=34594 obj=13.8387 num_tokens=606012 num_tokens/piece=17.5178\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=25945 obj=14.1301 num_tokens=637532 num_tokens/piece=24.5724\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25945 obj=14.0747 num_tokens=637568 num_tokens/piece=24.5738\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19458 obj=14.4091 num_tokens=670960 num_tokens/piece=34.4825\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19458 obj=14.3468 num_tokens=670999 num_tokens/piece=34.4845\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14593 obj=14.7196 num_tokens=705636 num_tokens/piece=48.3544\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14593 obj=14.648 num_tokens=705645 num_tokens/piece=48.355\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=10944 obj=15.0875 num_tokens=741620 num_tokens/piece=67.765\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=10944 obj=15.007 num_tokens=741624 num_tokens/piece=67.7654\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.3757 num_tokens=769363 num_tokens/piece=87.4276\n",
            "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.307 num_tokens=769367 num_tokens/piece=87.4281\n",
            "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
            "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 376816 Nov 29 11:33 korean_spm.model\r\n",
            "-rw-r--r-- 1 root root 146213 Nov 29 11:33 korean_spm.vocab\r\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
        "\n",
        "vocab_size = 8000\n",
        "\n",
        "with open(temp_file, 'w') as f:\n",
        "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
        "        f.write(str(row) + '\\n')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
        ")\n",
        "# 위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
        "\n",
        "!ls -l korean_spm*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6d1b1c",
      "metadata": {
        "id": "1a6d1b1c",
        "outputId": "8a06c41f-9ec1-41ee-ebb6-dc86af92360a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = spm.SentencePieceProcessor()\n",
        "s.Load('korean_spm.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f12794",
      "metadata": {
        "id": "d1f12794"
      },
      "outputs": [],
      "source": [
        "def sp_tokenize(s, corpus):\n",
        "\n",
        "    tensor = []\n",
        "\n",
        "    for sen in corpus:\n",
        "        tensor.append(s.EncodeAsIds(sen))\n",
        "\n",
        "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
        "        vocab = f.readlines()\n",
        "\n",
        "    word_index = {}\n",
        "    index_word = {}\n",
        "\n",
        "    for idx, line in enumerate(vocab):\n",
        "        word = line.split(\"\\t\")[0]\n",
        "\n",
        "        word_index.update({idx:word})\n",
        "        index_word.update({word:idx})\n",
        "\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, word_index, index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc7badf9",
      "metadata": {
        "id": "fc7badf9",
        "outputId": "e9c763ab-9499-405d-b504-8b3b4459cf67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 20)          100000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 8)                 928       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 101,009\n",
            "Trainable params: 101,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 이전 노드에서 썼었던 LSTM 모델 사용(1)\n",
        "\n",
        "vocab_size = 5000    # 어휘 사전의 크기\n",
        "word_vector_dim = 20  # 단어 하나를 표현하는 임베딩 벡터의 차원수 (변경가능)\n",
        "\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size,word_vector_dim))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35989b0",
      "metadata": {
        "id": "b35989b0",
        "outputId": "95625bdf-75a9-4863-f5a5-9c99f9dd0486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3056/3056 [==============================] - 17s 5ms/step - loss: 0.6620 - accuracy: 0.5764 - val_loss: 0.6281 - val_accuracy: 0.7025\n",
            "Epoch 2/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.6064 - accuracy: 0.7000 - val_loss: 0.6133 - val_accuracy: 0.6845\n",
            "Epoch 3/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.6147 - accuracy: 0.6689 - val_loss: 0.5978 - val_accuracy: 0.7101\n",
            "Epoch 4/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.5848 - accuracy: 0.7064 - val_loss: 0.5599 - val_accuracy: 0.7329\n",
            "Epoch 5/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.5399 - accuracy: 0.7399 - val_loss: 0.5283 - val_accuracy: 0.7493\n",
            "Epoch 6/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.4919 - accuracy: 0.7678 - val_loss: 0.4954 - val_accuracy: 0.7642\n",
            "Epoch 7/20\n",
            "3056/3056 [==============================] - 15s 5ms/step - loss: 0.4636 - accuracy: 0.7842 - val_loss: 0.4927 - val_accuracy: 0.7709\n",
            "Epoch 8/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.4426 - accuracy: 0.7949 - val_loss: 0.4645 - val_accuracy: 0.7775\n",
            "Epoch 9/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.4223 - accuracy: 0.8045 - val_loss: 0.4549 - val_accuracy: 0.7866\n",
            "Epoch 10/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.4052 - accuracy: 0.8128 - val_loss: 0.4499 - val_accuracy: 0.7895\n",
            "Epoch 11/20\n",
            "3056/3056 [==============================] - 17s 5ms/step - loss: 0.3908 - accuracy: 0.8209 - val_loss: 0.4527 - val_accuracy: 0.7927\n",
            "Epoch 12/20\n",
            "3056/3056 [==============================] - 17s 6ms/step - loss: 0.3795 - accuracy: 0.8272 - val_loss: 0.4512 - val_accuracy: 0.7925\n",
            "Epoch 00012: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1a61dd850>"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_input, train_target, epochs=20, validation_data=(val_input, val_target), callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaeba639",
      "metadata": {
        "id": "aaeba639"
      },
      "source": [
        "* vocab_size = 5000, word_vector_dim = 20 일 때의 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8645e714",
      "metadata": {
        "id": "8645e714",
        "outputId": "555eb87f-673a-4f45-8ef2-bf28a9d2289e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1284/1284 - 3s - loss: 0.4525 - accuracy: 0.7904\n",
            "[0.45252519845962524, 0.7904117107391357]\n"
          ]
        }
      ],
      "source": [
        "lstm_result = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(lstm_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2e0ee0",
      "metadata": {
        "id": "ff2e0ee0",
        "outputId": "3ab08a8a-f986-42a1-df07-8fc18ffb0de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, None, 20)          200000    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 8)                 928       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 201,009\n",
            "Trainable params: 201,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 이전 노드에서 썼었던 LSTM 모델 사용(2)\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기\n",
        "word_vector_dim = 20  # 단어 하나를 표현하는 임베딩 벡터의 차원수 (변경가능)\n",
        "\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size,word_vector_dim))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d94ef9",
      "metadata": {
        "id": "39d94ef9",
        "outputId": "79910eb1-27b0-4180-dcb3-3eb36468f99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3056/3056 [==============================] - 17s 5ms/step - loss: 0.5217 - accuracy: 0.7429 - val_loss: 0.4432 - val_accuracy: 0.8023\n",
            "Epoch 2/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.4139 - accuracy: 0.8174 - val_loss: 0.4087 - val_accuracy: 0.8125\n",
            "Epoch 3/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.3783 - accuracy: 0.8317 - val_loss: 0.4066 - val_accuracy: 0.8158\n",
            "Epoch 4/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.3563 - accuracy: 0.8408 - val_loss: 0.4038 - val_accuracy: 0.8183\n",
            "Epoch 5/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.3387 - accuracy: 0.8501 - val_loss: 0.4060 - val_accuracy: 0.8217\n",
            "Epoch 6/20\n",
            "3056/3056 [==============================] - 16s 5ms/step - loss: 0.3236 - accuracy: 0.8586 - val_loss: 0.4043 - val_accuracy: 0.8165\n",
            "Epoch 00006: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1321ad070>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_input, train_target, epochs=20, validation_data=(val_input, val_target), callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a17ea3a4",
      "metadata": {
        "id": "a17ea3a4"
      },
      "source": [
        "* 위와 같이 vocab_size = 10000 으로 키웠을 때의 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a763c2",
      "metadata": {
        "id": "c4a763c2",
        "outputId": "e52fb59e-64b7-4e43-b3b8-61f950435cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1284/1284 - 3s - loss: 0.4014 - accuracy: 0.8185\n",
            "[0.401365727186203, 0.8184850811958313]\n"
          ]
        }
      ],
      "source": [
        "lstm_result = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(lstm_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b391a2a",
      "metadata": {
        "id": "7b391a2a"
      },
      "source": [
        "### 형태소 기반 토큰화와 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c0839f7",
      "metadata": {
        "id": "0c0839f7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "from MeCab import Tagger\n",
        "\n",
        "tokenizer = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "def load_data(train_data, test_data, num_words=10000):\n",
        "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    train_data = train_data.dropna(how = 'any') \n",
        "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    test_data = test_data.dropna(how = 'any') \n",
        "    \n",
        "    X_train = []\n",
        "    for sentence in train_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
        "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "        X_train.append(temp_X)\n",
        "\n",
        "    X_test = []\n",
        "    for sentence in test_data['document']:\n",
        "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
        "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "        X_test.append(temp_X)\n",
        "    \n",
        "    words = np.concatenate(X_train).tolist()\n",
        "    counter = Counter(words)\n",
        "    counter = counter.most_common(10000-4)\n",
        "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
        "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
        "        \n",
        "    def wordlist_to_indexlist(wordlist):\n",
        "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
        "        \n",
        "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
        "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
        "        \n",
        "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
        "    \n",
        "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4be730e",
      "metadata": {
        "id": "d4be730e"
      },
      "outputs": [],
      "source": [
        "index_to_word = {index:word for word, index in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef26d04",
      "metadata": {
        "id": "7ef26d04",
        "outputId": "479e10e5-795c-4f34-e972-c95672782cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<UNUSED>\n"
          ]
        }
      ],
      "source": [
        "# 비어있는 것들에 할당\n",
        "\n",
        "word_to_index[\"<PAD>\"] = 0\n",
        "word_to_index[\"<BOS>\"] = 1\n",
        "word_to_index[\"<UNK>\"] = 2  # unknown\n",
        "word_to_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "index_to_word = {index:word for word, index in word_to_index.items()}\n",
        "\n",
        "print(index_to_word[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44142aff",
      "metadata": {
        "id": "44142aff",
        "outputId": "21723763-99f2-4914-ec5d-7fb37547f6d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(120122, 50)\n"
          ]
        }
      ],
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        value=word_to_index[\"<PAD>\"],\n",
        "                                                        padding='pre', # 혹은 'post'\n",
        "                                                        maxlen=50)\n",
        "\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=word_to_index[\"<PAD>\"],\n",
        "                                                       padding='pre', # 혹은 'post'\n",
        "                                                       maxlen=50)\n",
        "\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1addf703",
      "metadata": {
        "id": "1addf703"
      },
      "outputs": [],
      "source": [
        "# validation set 만들기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 일반적으로 훈련 데이터셋과 검증 데이터셋은 8:2 로 나눈다.\n",
        "train_input, val_input, train_target, val_target = train_test_split(X_train, y_train, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    random_state=34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8228b950",
      "metadata": {
        "id": "8228b950",
        "outputId": "c48d89c1-2ba1-4fc8-95e2-63b78581620d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 20)          200000    \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 8)                 928       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 201,009\n",
            "Trainable params: 201,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 이전 노드에서 썼었던 LSTM 모델 사용(3)\n",
        "\n",
        "vocab_size = 10000    # 어휘 사전의 크기\n",
        "word_vector_dim = 20  # 단어 하나를 표현하는 임베딩 벡터의 차원수 (변경가능)\n",
        "\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size,word_vector_dim))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a72e7d9",
      "metadata": {
        "id": "4a72e7d9",
        "outputId": "3f5507c9-4a64-4f50-f981-79250635b476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3004/3004 [==============================] - 17s 5ms/step - loss: 0.4039 - accuracy: 0.8157 - val_loss: 0.3649 - val_accuracy: 0.8362\n",
            "Epoch 2/20\n",
            "3004/3004 [==============================] - 16s 5ms/step - loss: 0.3268 - accuracy: 0.8564 - val_loss: 0.3538 - val_accuracy: 0.8432\n",
            "Epoch 3/20\n",
            "3004/3004 [==============================] - 16s 5ms/step - loss: 0.2898 - accuracy: 0.8744 - val_loss: 0.3548 - val_accuracy: 0.8450\n",
            "Epoch 4/20\n",
            "3004/3004 [==============================] - 16s 5ms/step - loss: 0.2599 - accuracy: 0.8893 - val_loss: 0.3706 - val_accuracy: 0.8440\n",
            "Epoch 00004: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc0598bbd60>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1) \n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_input, train_target, epochs=20, validation_data=(val_input, val_target), callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b48cee",
      "metadata": {
        "id": "b2b48cee"
      },
      "source": [
        "* 위와 같이 형태소 기반 토큰화인 MeCab 을 사용했을 때의 결과는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40e5493",
      "metadata": {
        "id": "c40e5493",
        "outputId": "b3bf4517-f0bc-4923-a828-042919f4cc55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1266/1266 - 3s - loss: 0.3671 - accuracy: 0.8431\n",
            "[0.3670845031738281, 0.8430593013763428]\n"
          ]
        }
      ],
      "source": [
        "lstm_result = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(lstm_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4b2fba",
      "metadata": {
        "id": "ae4b2fba"
      },
      "source": [
        "### 결과\n",
        "\n",
        "같은 조건에서 SentencePiece 토크나이저를 사용했을 때는 정확도가 81.8% 를 기록했다.\n",
        "반면 형태소 기반 토크나이저 MeCab을 사용했을 때는 정확도가 84.3% 를 기록했다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900ad620",
      "metadata": {
        "id": "900ad620"
      },
      "source": [
        "# 회고\n",
        "\n",
        "이번 노드에서는 센텐스피스를 활용해 토큰화하여 모델에 적용해보았다. 비록 이번 프로젝트에서는 형태소 기반 토크나이저인 MeCab 이 조금 더 높은 정확도를 보였으나 센텐스피스는 비교적 간단하게 언어에 상관없이 적용할 수 있기 때문에 이 정도 차이는 충분히 무시할만하다고 보인다. 특히 영어 같은 언어와는 달리 한국어는 교착어로, 토큰화가 매우 힘든 편에 속한다. 그럼에도 불구하고 한국어 전용 토크나이저와 비슷한 수준의 성능을 보인다는 점에서 충분히 가능성을 볼 수 있었다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fa2d95",
      "metadata": {
        "id": "36fa2d95"
      },
      "source": [
        "# Reference\n",
        "\n",
        "https://wikidocs.net/86657 SentencePiece 에 대해"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}